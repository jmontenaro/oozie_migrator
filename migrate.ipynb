{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc821eca-d455-4b3e-9724-1e1165601375",
   "metadata": {},
   "source": [
    "## Migrating Oozie Workflows to Airflow CDE DAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a92a02-5995-472c-8922-8bcf981e3c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acce28ea-eefd-4d48-a261-a3da03aaaec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.local/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: requests_toolbelt in ./.local/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.1 in /usr/local/lib/python3.7/site-packages (from requests_toolbelt) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.1->requests_toolbelt) (2020.11.8)\n",
      "Requirement already satisfied: xmltodict in ./.local/lib/python3.7/site-packages (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install requests_toolbelt\n",
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2694c89-d7b2-48d7-97bf-c6880fe647ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import migration_utility.workflow as workflow\n",
    "import migration_utility.cdejob as cdejob\n",
    "import migration_utility.cderesource as cderesource\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f2d351-dd33-4cc1-ac15-c9addd48c36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_input_dir = 'input'\n",
    "project_output_dir = 'output'\n",
    "\n",
    "dag_file = 'combined.py'\n",
    "dag_name = 'combined'\n",
    "\n",
    "cde_prefix = 'jmontenaro_combined'\n",
    "cde_resource_name = 'resource'\n",
    "cde_job_name = 'job'\n",
    "\n",
    "hive_connection = 'default-hive-aws'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83aba04f-4cfc-49da-b5cd-de181d782ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"WORKLOAD_USER\"] = \"jmontenaro\"\n",
    "os.environ[\"WORKLOAD_PASSWORD\"] = \"Cloudera#123\"\n",
    "os.environ[\"JOBS_API_URL\"] = \"https://zph56zmm.cde-ntvvr5hx.go01-dem.ylcu-atmi.cloudera.site/dex/api/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873dbcb8-da3b-49c9-a6ff-647e294a844f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {project_output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03f16e9-1786-4edf-a6f6-f508f43d32ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ow = workflow.OozieWorkflow(project_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e356e47b-6a37-457e-8f9f-4724f2a86aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oozie workflow file workflow.xml found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'workflow-app': {'@xmlns': 'uri:oozie:workflow:0.4',\n",
       "  '@name': 'combined-workflow',\n",
       "  'start': {'@to': 'spark_pi'},\n",
       "  'action': [{'@name': 'spark_pi',\n",
       "    'spark': {'@xmlns': 'uri:oozie:spark-action:0.1',\n",
       "     'job-tracker': '${jobTracker}',\n",
       "     'name-node': '${nameNode}',\n",
       "     'prepare': {'delete': {'@path': '${nameNode}/user/jmontenaro/spark_pi/output-data'}},\n",
       "     'master': '${master}',\n",
       "     'mode': '${mode}',\n",
       "     'name': 'spark_pi',\n",
       "     'class': 'org.apache.spark.examples.SparkPi',\n",
       "     'jar': 'example_spark_jobs/jobs/pi.scala',\n",
       "     'spark-opts': '--executor-memory 2G --num-executors 5',\n",
       "     'arg': 'value=10'},\n",
       "    'ok': {'@to': 'show_databases'},\n",
       "    'error': {'@to': 'kill_job'}},\n",
       "   {'@name': 'show_databases',\n",
       "    'hive': {'@xmlns': 'uri:oozie:hive-action:0.4',\n",
       "     'job-tracker': '${jobTracker}',\n",
       "     'name-node': '${nameNode}',\n",
       "     'script': '${script_show_databases}'},\n",
       "    'ok': {'@to': 'end'},\n",
       "    'error': {'@to': 'kill_job'}}],\n",
       "  'kill': {'@name': 'kill_job', 'message': 'Job failed'},\n",
       "  'end': {'@name': 'end'}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_dict = ow.create_workflow_dict()\n",
    "workflow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e691bfcf-6616-42ff-9ea5-db65bc87aa7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties file job.properties found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nameNode': 'hdfs://mynameservice',\n",
       " 'master': 'local',\n",
       " 'mode': 'client',\n",
       " 'jobTracker': 'myjobtracker:8088',\n",
       " 'script_show_databases': 'input/show_databases.hive'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_props = ow.create_workflow_props()\n",
    "workflow_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97b123e-04c1-43cb-b31f-64833f0cf895",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workflow-app': {'@xmlns': 'uri:oozie:workflow:0.4',\n",
       "  '@name': 'combined-workflow',\n",
       "  'start': {'@to': 'spark_pi'},\n",
       "  'action': [{'@name': 'spark_pi',\n",
       "    'spark': {'@xmlns': 'uri:oozie:spark-action:0.1',\n",
       "     'job-tracker': 'myjobtracker:8088',\n",
       "     'name-node': 'hdfs://mynameservice',\n",
       "     'prepare': {'delete': {'@path': 'hdfs://mynameservice}/user/jmontenaro/spark_pi/output-data'}},\n",
       "     'local': '${local',\n",
       "     'client': 'client',\n",
       "     'name': 'spark_pi',\n",
       "     'class': 'org.apache.spark.examples.SparkPi',\n",
       "     'jar': 'example_spark_jobs/jobs/pi.scala',\n",
       "     'spark-opts': '--executor-memory 2G --num-executors 5',\n",
       "     'arg': 'value=10'},\n",
       "    'ok': {'@to': 'show_databases'},\n",
       "    'error': {'@to': 'kill_job'}},\n",
       "   {'@name': 'show_databases',\n",
       "    'hive': {'@xmlns': 'uri:oozie:hive-action:0.4',\n",
       "     'job-tracker': 'myjobtracker:8088',\n",
       "     'name-node': 'hdfs://mynameservice',\n",
       "     'script': 'input/show_databases.hive'},\n",
       "    'ok': {'@to': 'end'},\n",
       "    'error': {'@to': 'kill_job'}}],\n",
       "  'kill': {'@name': 'kill_job', 'message': 'Job failed'},\n",
       "  'end': {'@name': 'end'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_dict = ow.replace_workflow_props(workflow_dict, workflow_props)\n",
    "workflow_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef51b4a-60a2-4a46-b3b5-033236d851ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cj = cdejob.CDEJob(workflow_dict, hive_connection, cde_prefix, cde_resource_name, dag_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e951158-ff55-4948-8a76-1504c22f4d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cj.initialize_dag(project_output_dir, dag_file)\n",
    "cj.dag_imports(project_output_dir, dag_file)\n",
    "cj.dag_declaration('jmontenaro', project_output_dir, dag_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20fd907f-bff5-48c3-8143-2ef23a5285ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Job Name: spark_pi\n",
      "Working on Spark CDE Job: jmontenaro_combined_spark_pi\n",
      "Converted Spark Oozie Action into Spark CDE Payload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'jmontenaro_combined_spark_pi',\n",
       "  'type': 'spark',\n",
       "  'retentionPolicy': 'keep_indefinitely',\n",
       "  'mounts': [{'dirPrefix': '/',\n",
       "    'resourceName': 'jmontenaro_combined_resource'}],\n",
       "  'spark': {'file': 'pi.scala',\n",
       "   'conf': {'spark.pyspark.python': 'python3'},\n",
       "   'executorMemory': '2G',\n",
       "   'numExecutors': 5},\n",
       "  'schedule': {'enabled': False}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_payloads = cj.parse_oozie_workflow(project_output_dir, dag_file, workflow_dict)\n",
    "spark_payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24dc067d-f163-41b6-b8d6-2b813eb90500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Airflow DAG ###\n",
      "\n",
      "import pendulum\n",
      "\n",
      "from airflow import DAG\n",
      "from cloudera.cdp.airflow.operators.cdw_operator import CDWOperator\n",
      "from cloudera.cdp.airflow.operators.cde_operator import CDEJobRunOperator\n",
      "from dateutil import parser\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "default_args = {\n",
      "    'owner': 'jmontenaro',\n",
      "    'retry_delay': timedelta(seconds=5),\n",
      "    'depends_on_past': False,\n",
      "    'start_date': pendulum.datetime(2016, 1, 1, tz=\"Europe/Amsterdam\")\n",
      "}\n",
      "\n",
      "combined = DAG (\n",
      "    'combined-pipeline-demo',\n",
      "    default_args=default_args,\n",
      "    schedule_interval='@daily',\n",
      "    catchup=False,\n",
      "    is_paused_upon_creation=False\n",
      ")\n",
      "\n",
      "spark_pi_step = CDEJobRunOperator (\n",
      "    task_id='spark_pi',\n",
      "    dag=combined,\n",
      "    job_name='jmontenaro_combined_spark_pi'\n",
      ")\n",
      "\n",
      "cdw_query = \"\"\"show databases;\"\"\"\n",
      "\n",
      "show_databases_step = CDWOperator (\n",
      "    task_id=\"show_databases\",\n",
      "    dag=combined,\n",
      "    cli_conn_id=\"default-hive-aws\",\n",
      "    hql=cdw_query,\n",
      "    schema='default',\n",
      "    use_proxy_user=False,\n",
      "    query_isolation=True\n",
      ")\n",
      "\n",
      "spark_pi_step >> show_databases_step\n"
     ]
    }
   ],
   "source": [
    "with open(project_output_dir + \"/\" + dag_file, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0a2b7d2-bf0f-4e05-9901-0836b000b548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Airflow CDE Job: jmontenaro_combined_job\n",
      "Converted DAG into Airflow CDE Payload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'type': 'airflow',\n",
       " 'airflow': {'dagFile': 'combined.py'},\n",
       " 'identity': {'disableRoleProxy': True},\n",
       " 'mounts': [{'dirPrefix': '/',\n",
       "   'resourceName': 'jmontenaro_combined_resource'}],\n",
       " 'name': 'jmontenaro_combined_job',\n",
       " 'retentionPolicy': 'keep_indefinitely'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airflow_cde_payload = cj.oozie_to_cde_airflow_payload(dag_file, cde_resource_name, cde_job_name)\n",
    "airflow_cde_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d93275f-4aa7-48e9-923d-caa02ccbff05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cr = cderesource.CDEResource(os.environ[\"JOBS_API_URL\"], os.environ[\"WORKLOAD_USER\"], cde_prefix, cde_resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c711693-4a3a-4ff9-b40b-5e3500c20509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = cr.set_cde_token(os.environ[\"WORKLOAD_PASSWORD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef6ca614-31ef-498f-a272-0d1917167601",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr.create_cde_resource(token, cde_resource_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb0d0b84-cb12-4a10-bf53-fa1ff145b66f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Job: pi.scala\n",
      "Response Status Code 201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr.upload_file(cde_resource_name, project_input_dir, \"pi.scala\", token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9caa2496-8a98-47cf-b769-42daf661a0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Job: jmontenaro_combined_spark_pi\n",
      "Response Status Code 201\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for spark_payload in spark_payloads:\n",
    "    cr.create_job_from_resource(token, spark_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18444cb5-8711-41a1-9d87-a9025de35d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Job: combined.py\n",
      "Response Status Code 201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr.upload_file(cde_resource_name, project_output_dir, dag_file, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0720695b-e441-4866-aaae-e4ed175799d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Job: jmontenaro_combined_job\n",
      "Response Status Code 201\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr.create_job_from_resource(token, airflow_cde_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dc129-bb1d-406a-b78f-2c13f945fe54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
